---
layout: post
title: Convolutional Neural Network (CNN)
category: deep learning
post-series: Deep learning from scratch
post-order: 19
---

이전 [post](https://gyuhub.github.io/posts/study/machine%20learning/deep%20learning/learning-techniques-3)까지는 학습 관련 기술들에 대해서 배웠습니다. 이번 post부터는 **합성곱 신경망**(Convolutional Neural Network, CNN)에 대해서 알아보겠습니다. CNN은 **이미지 인식**과 **음성 인식** 등 다양한 곳에서 사용되는데, 특히 이미지 인식 분야에서 딥러닝을 활용한 기법은 거의 다 CNN을 **기초**로 합니다. 따라서 CNN의 **메커니즘**을 자세히 알아보고 이를 Python으로 구현해보겠습니다.

---

# 전체 구조

우선 CNN의 네트워크 구조를 살펴보면서 전체 틀을 설명해보겠습니다. CNN도 지금까지 본 신경망과 같이 레고 블록처럼 <ins>계층을 조합하여</ins> 만들 수 있습니다. 다만, **합성곱 계층**(convolutional layer)과 **풀링 계층**(pooling layer)이 새롭게 등장합니다. 합성곱 계층과 풀링 계층의 상세 내용은 잠시 후 설명하기로 하고, 이 계층들을 어떻게 조합하여 CNN을 만드는지를 먼저 살펴보겠습니다.

지금까지 본 신경망은 인접하는 계층의 **모든 뉴런**과 결합되어 있었습니다. 이를 **완전연결**(fully-connected, 전결합)이라고 하며, 완전히 연결된 계층을 **Affine 계층**이라는 이름으로 구현했습니다. 이 Affine 계층을 사용해서 층이 5개인 완전연결 신경망은 다음과 같이 구현할 수 있었습니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_1.png"
         title="Fully connected neural network"
         alt="Image of fully connected neural network"
         class="img_center"
         style="width: 70%"/>
    <figcaption>완전연결 신경망의 예</figcaption>
</figure>

[Fig. 1.]과 같이 완전연결 신경망은 **Affine 계층** 뒤에 **활성화 함수**를 갖는 **ReLU 계층** (혹은 **Sigmoid 계층**)이 이어집니다. 위 그림에서는 Affine-ReLU 조합이 4개가 쌓였고, 마지막 5번째 층은 Affine 계층에 이어 소프트맥스 계층에서 최종 결과(확률)를 출력합니다. 이 예시에 CNN의 구조를 반영해보겠습니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_2.png"
         title="Convolutional neural network"
         alt="Image of convolutional neural network"
         class="img_center"
         style="width: 70%"/>
    <figcaption>CNN의 예</figcaption>
</figure>

[Fig. 2.]와 같이 CNN에서는 새로운 **합성곱 계층**(Conv)과 **풀링 계층**(Pooling)이 추가됩니다. CNN의 계층은 "Conv-ReLU-(Pooling)" 구성으로 연결됩니다(풀링 계층은 **생략**하기도 합니다). 또한 주목할 또 다른 점은 출력에 가까운 층에서는 지금까지의 "Affine-ReLU" 구성을 사용할 수 있다는 것입니다. 또, 마지막 출력 계층에서는 "Affine-Softamx" 구성을 그대로 사용합니다. 이상이 일반적인 CNN에서 흔히 볼 수 있는 구성입니다.

# 합성곱 계층

CNN에서는 **패딩**(padding), **스트라이드**(stride) 등 CNN 고유의 용어가 등장합니다. 또, 각 계층 사이에는 3차원 데이터같이 **입체적인** 데이터가 흐른다는 점에서 완전연결 신경망과 다릅니다.

지금까지 본 완전연결 신경망에서는 **완전연결 계층**(Affine 계층)을 사용했습니다. 완전연결 계층에서는 인접하는 계층의 뉴런이 **모두 연결되고** 출력의 수는 임의로 정할 수 있습니다. 이러한 완전연결 계층의 문제점은 무엇일까요? 바로 "**데이터의 형상**"이 '**무시**'된다는 사실입니다. 입력 데이터가 이미지인 경우를 예로 들면, 이미지는 통상 세로 &bull; 가로 &bull; 채널(색상)로 구성된 **3차원** 데이터입니다. 그러나 완전연결 계층에 입력할 때는 3차원 데이터를 평평한 **1차원** 데이터로 평탄화해줘야합니다.

이미지는 3차원 형상이며, 이 형상에는 중요한 **공간적 정보**가 담겨 있습니다. 예를 들어 *공간적으로 가까운* 픽셀은 값이 **비슷**하거나, RGB의 *각 채널*은 서로 밀접하게 **관련**되어 있거나, *거리가 먼* 픽셀끼리는 별 연관이 **없는** 등, 3차원 속에서 의미를 갖는 본질적인 **패턴**이 숨어 있을 것입니다. 그러나 완전연결 계층은 데이터의 형상을 무시하고 모든 입력 데이터를 동등한 뉴런(**같은 차원**의 뉴런)으로 취급하여 형상에 담긴 정보를 살릴 수 없습니다.

한편, 합성곱 계층은 형상을 **유지**합니다. 이미지도 3차원 데이터로 입력받으며, 마찬가지로 다음 계층에도 3차원 데이터로 전달합니다. 그래서 CNN에서는 이미지처럼 **형상을 가진 데이터**를 제대로 **이해**할 (가능성이 있는) 것입니다.

CNN에서는 합성곱 계층의 입출력 데이터를 **특징 맵**(feature map)이라고도 합니다. 합성곱 계층의 입력 데이터를 **입력 특징 맵**(input feature map), 출력 데이터를 **출력 특징 맵**(output feature map)이라고 하는 식입니다.

> 💁‍♂️ 앞으로 CNN에 대해서 설명할 때, **입출력 데이터**와 **특징 맵**을 같은 의미로 사용하겠습니다.

## 합성곱 연산

**합성곱 계층**에서는 **합성곱 연산**을 처리합니다. 합성곱 연산은 이미지 처리에서 말하는 **필터 연산**에 해당합니다. 구체적인 예를 들어보겠습니다.

> 👨‍🏫 합성곱은 공학과 물리학에서 널리 쓰이는 수학적 개념으로, 간단히 정의해보면 다음과 같습니다.<br>
> ▶️ 두 함수 중 하나를 반전(reverse), 이동(shift)시키며 나머지 함수와의 곱을 연이어 적분한다.<br>
> <small>합성곱에 대한 더 자세한 정의는 [여기](https://en.wikipedia.org/wiki/Convolution)를 참고해주시면 감사하겠습니다.</small>

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_3.png"
         title="Example of convolution"
         alt="Image of example of convolution"
         class="img_center"
         style="width: 70%"/>
    <figcaption>합성곱 연산의 예</figcaption>
</figure>

[Fig. 3.]과 같이 합성곱 연산은 **입력 데이터**(좌)에 **필터**(우)를 적용합니다. 이 예에서 입력 데이터는 세로 &bull; 가로의 방향성을 가졌고, 필터 역시 세로 &bull; 가로의 방향의 차원을 갖습니다. 데이터와 필터의 형상을 (높이<sup>height</sup>, 너비<sup>width</sup>)로 표기하며, 이 예에서 입력은 (4, 4), 필터는 (3, 3), 출력은 (2, 2)가 됩니다. 문헌에 따라 필터를 **커널**이라고 칭하기도 합니다.

[Fig. 3.]의 합성곱 연산의 예에서 어떤 계산이 이뤄지는지 설명하겠습니다. 합성곱 연산은 필터의 **윈도우**(window)를 일정 간격으로 이동해가며 입력 데이터에 적용합니다. 여기에서 말하는 윈도우는 아래 그림의 **회색 부분(3 X 3)**을 가리킵니다. 입력과 필터에서 **대응하는 원소**끼리 곱한 후 그 **총합**을 구합니다(이 계산을 단일 곱셈-누산<sup>Fused Multiply Add, FMA</sup>이라 합니다). 그리고 그 결과를 출력의 **해당 장소**에 저장합니다. 이 과정을 모든 장소에서 수행하면 합성곱 연산의 출력이 완성됩니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_4.png"
         title="Computation order of convolution"
         alt="Image of computation order of convolution"
         class="img_center"
         style="width: 60%"/>
    <img src="/posts/study/machine learning/deep learning/images/cnn_5.png"
         title="Computation order of convolution"
         alt="Image of computation order of convolution"
         class="img_center"
         style="width: 60%"/>
    <figcaption>합성곱 연산의 계산 순서</figcaption>
</figure>

[Fig. 4.]를 통해서 합성곱 연산이 어떻게 이루어지는지 대략적인 느낌 정도는 알 수 있을 것 같습니다.

---

CNN에 대해서 좀 더 파고들기 전에 합성곱의 수식과 그래프를 통해서 깊게 알아보겠습니다. 수식으로는 다음과 같습니다.

> <p class="message"> 📋 만약 합성곱 연산에 대해서 잘 알고 계시다면 이 부분은 넘어가셔도 좋습니다😄. <a href="#편향">넘어가기</a></p>

$$
(f*g)(t) := \int_{-\infty}^{\infty} f(\tau)g(t-\tau), d\tau. \label{convolution} \tag{1}
$$

식 $(\ref{convolution})$에서 $t$라는 기호가 사용되었는데, 꼭 시간 영역에서의 $t$가 아니여도 됩니다. 각각의 $t$마다 합성곱 수식은 함수 $f(\tau)$에 $t$만큼 이동(shitf)한 $g(-\tau)$가 곱해진 영역을 나타내게 됩니다. 또한, $t$가 변하게 되면서 곱해지는 함수 $g(-\tau)$는 입력 함수인 $f(\tau)$의 또다른 부분을 <ins>강조</ins>하게 됩니다. 중요한 것은 함수 $f,g$의 정의역은 $[0, \infty)$의 부분집합이라는 것입니다(음의 영역에 대해서는 0). 그래서 식 $(\ref{convolution})$은 다음과 같이 바뀔 수 있습니다.

$$
(f*g)(t) := f(t)*g(t) := \int_{0}^{t} f(\tau)g(t-\tau), d\tau\ \text{for} f,g: [0,\infty)\rightarrow \mathbb{R}. \tag{2}
$$

그럼 그래프를 통해서 합성곱 연산을 알아보겠습니다. 결과는 다음과 같습니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_6.gif"
         title="Visualization of convolution"
         alt="Image of visualization of convolution"
         class="img_center"
         style="width: 55%"/>
    <figcaption>합성곱 연산의 시각화</figcaption>
</figure>

[Fig. 5.]에서는 입력 신호 $f(t)$에 필터 $g(t)$를 사용해서 합성곱 연산을 진행하는 모습을 볼 수 있습니다. 각각의 함수는 아래와 같습니다.

$$
\begin{matrix}
f(t)&=&\begin{cases}
t-1\ (1 \le t < 2.5) \\
-(t-4)\ (2.5 \le t < 4) \\
0\ (\text{otherwise})
\end{cases}, \\
g(t)&=&\begin{cases}
1\ (\left \vert t \right \vert \le 1) \\
0\ (\text{otherwise}) 
\end{cases}.
\end{matrix} \tag{3}
$$

입력 신호를 필터가 이동하면서 겹쳐진 부분이 많아질수록 합성곱 연산의 결과도 동시에 커지고, 겹치는 부분이 적을수록 합성곱 연산의 결과도 작아지는 것을 통해서 합성곱 연산의 원리를 이해할 수 있을 것 같습니다.

---

## 편향

완전연결 신경망에는 **가중치 매개변수**와 **편향**이 존재하는데, CNN에서는 필터의 매개변수가 그동안의 '**가중치**'에 해당합니다. 그리고 CNN에도 편향이 존재합니다. [Fig. 3.]은 필터를 적용하는 단계까지만 보여준 것이고, 편향까지 포함하면 다음과 같은 흐름이 됩니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_7.png"
         title="Bias of convolution"
         alt="Image of bias of convolution"
         class="img_center"
         style="width: 60%"/>
    <figcaption>합성곱 연산의 편향</figcaption>
</figure>

[Fig. 6]과 같이 편향은 필터를 적용한 후의 데이터에 더해집니다. 그리고 편향은 항상 **하나**(1x1)만 존재합니다. 그 하나의 값을 필터를 적용한 모든 원소에 더하는 것이죠.

## 패딩

합성곱 연산을 수행하기 전에 입력 데이터 주변을 **특정 값**(예컨대 0)으로 채우기도 합니다. 이를 **패딩**(padding)이라 하며, 합성곱 연산에서 자주 이용하는 기법입니다. 예를 하나 들어보겠습니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_8.png"
         title="Example of padding"
         alt="Image of example of padding"
         class="img_center"
         style="width: 60%"/>
    <figcaption>합성곱 연산의 패딩 처리의 예</figcaption>
</figure>

[Fig. 7.]에서는 입력 데이터(4x4)에 **폭이 1인** 패딩을 적용한 모습입니다. 폭 **1**짜리 패딩이라 하면 입력 데이터 사방 **1픽셀**을 **특정 값**으로 채우는 것입니다. 이 예시에서는 특정 값을 0으로 채웠습니다(그림 안에서는 표기하지 않고 생략했습니다). 또한, 이 예에서는 패딩을 1로 설정했지만, 2나 3 등 원하는 정수로 설정할 수 있습니다.

> 👨‍🏫 패딩은 주로 **출력 크기**를 **조정**할 목적으로 사용됩니다. 기존의 합성곱 연산은 입력 데이터(4x4)에 필터(3x3)를 적용하면 출력 데이터의 크기는 (2x2)가 되어, 입력보다 2만큼 줄어듭니다. 이는 합성곱 연산을 몇 번이나 되풀이하는 심층 신경망에서는 문제가 될 수 있습니다. 합성곱 연산을 거칠 때마다 **크기가 작아지면** 어느 시점에서는 출력 크기가 **1**이 되어버리겠죠. 더 이상은 합성곱 연산을 적용할 수 **없다**는 뜻입니다.<br>
> 
> 이러한 사태를 막기 위해서 **패딩**을 사용합니다. 패딩을 적용한 합성곱 연산은 입력 데이터(4x4)에 폭이 1인 패딩을 적용하니 출력 데이터의 크기가 입력 데이터의 크기와 **같은** (4x4)로 유지되었습니다. 한 마디로 <ins>입력 데이터의 공간적 크기를 고정</ins>한 채로 다음 계층에 <ins>전달</ins>할 수 있습니다.

## 스트라이드

필터의 적용하는 **위치의 간격**을 **스트라이드**(stride)라고 합니다. 지금까지 본 예는 모두 스트라이드가 1이었지만, 예를 들어 스트라이드를 **3**로 하면 필터를 적용하는 **윈도우**가 **세 칸씩** 이동합니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_9.png"
         title="Example of stride"
         alt="Image of example of strid"
         class="img_center"
         style="width: 60%"/>
    <img src="/posts/study/machine learning/deep learning/images/cnn_10.png"
         title="Example of stride"
         alt="Image of example of strid"
         class="img_center"
         style="width: 60%"/>
    <figcaption>합성곱 연산의 스트라이드 처리의 예</figcaption>
</figure>

[Fig. 8.]에서는 크기가 (6x6)인 입력 데이터에 스트라이드를 3으로 설정한 필터를 적용합니다. 이처럼 **스트라이드**는 필터를 적용하는 **간격**을 지정합니다. 그런데 스트라이드를 3으로 하니 출력 데이터의 크기는 (3x3)이 되는군요. 이처럼 스트라이드를 <ins>키우면</ins> 출력 데이터의 크기는 <ins>작아집니다</ins>. 한편, 패딩을 <ins>크게</ins> 하면 출력이 <ins>커졌습니다</ins>. 이러한 관계는 수식화가 가능합니다. 수식은 다음과 같습니다.

$$
OH=\frac{H+2P-FH}{S} + 1, \\
OW=\frac{W+2P-FW}{S} + 1. \label{size_of_output} \tag{4}
$$

식 $(\ref{size_of_output})$에서는 입력 데이터의 크기를 $(H,W)$, 필터의 크기를 $(FH,FW)$, 출력 데이터의 크기를 $(OH,OW)$, 패딩을 $P$, 스트라이드를 $S$로 나타냈습니다. 단, 식 $(\ref{size_of_output})$의 **분수**들은 정수로 **나눠떨어지는** 값이어야 한다는 점에 주의해야 합니다. 왜냐하면 계산되는 값이 출력 데이터의 원소의 개수라는 정수이기 때문입니다. 만약 정수로 나눠떨어지지 않는다면 가장 가까운 정수로 반올림하는 등의 예외처리를 진행하면 되겠습니다.

# 3차원 데이터의 합성곱 연산

지금까지 2차원 형상을 다루는 합성곱 연산을 살펴봤습니다. 그러나 이미지만 해도 세로 &bull; 가로에 더해서 채널까지 고려한 **3차원** 데이터입니다. 이번 절에서는 조금 전과 같은 순서로, 채널까지 고려한 3차원 데이터를 다루는 합성곱 연산을 살펴보겠습니다. 먼저 3차원 데이터의 합성곱 연산 예를 들어보겠습니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_11.png"
         title="Example of 3-D convolution"
         alt="Image of example of 3-D convolution"
         class="img_center"
         style="width: 70%"/>
    <figcaption>3차원 데이터 합성곱 연산의 예</figcaption>
</figure>

[Fig. 9.]는 3차원 데이터의 합성곱 연산의 예입니다. 2차원일 때와 비교하면, **길이** 방향(**채널** 방향)으로 **특징 맵**이 늘어났습니다. 채널쪽으로 특징 맵이 여러 개 있다면 입력 데이터와 필터의 합성곱 연산을 **채널마다** 수행하고, 그 결과를 **더해서** **하나**의 출력을 얻습니다. 계산 순서를 좀 더 명확하게 해보겠습니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_12.gif"
         title="Computation order of 3-D convolution"
         alt="Image of computation order of 3-D convolution"
         class="img_center"
         style="width: 70%"/>
    <figcaption>3차원 데이터 합성곱 연산의 계산 순서</figcaption>
</figure>

[Fig. 10.]은 3차원 데이터의 합성곱 연산의 계산 순서를 나타낸 그림입니다. 3차원 합성곱 연산에서 주의할 점은 **입력 데이터의 채널 수**와 **필터의 채널 수**가 같아야 한다는 것입니다. 한편, 필터 자체의 **크기**는 원하는 값으로 설정할 수 있습니다(단, 모든 채널의 필터가 **같은** 크기여야 합니다).

3차원의 합성곱 연산은 데이터와 필터를 직육면체 블록이라고 생각하면 이해하기 쉽습니다. 블록은 아래 그림과 같은 3차원 직육면체입니다. 앞으로 설명의 용이함을 위해서 3차원 데이터를 배열로 나타낼 때는 (**채널**<sup>channel</sup>, **높이**<sup>height</sup>, **너비**<sup>width</sup>) 순서로 표기하겠습니다. 예를 들어 채널 수 **C**, 높이 **H**, 너비 **W**인 데이터의 형상은 (**C**, **H**, **W**)로 씁니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_13.png"
         title="Cuboid form of 3-D convolution"
         alt="Image of cuboid form of 3-D convolution"
         class="img_center"
         style="width: 70%"/>
    <figcaption>3차원 합성곱 연산의 직육면체 형상</figcaption>
</figure>

[Fig. 11.]의 예시는 출력 데이터가 한 장의 특징 맵인 경우입니다. 한 장의 특징 맵을 다른 말로 하면 **채널**이 **1**개인 특징 맵이라고 할 수 있습니다. 그럼 합성곱 연산의 출력으로 다수의 채널을 내보내려면 어떻게 하면 될까요? 그 해답은 바로 필터(가중치)를 다수 사용하는 것입니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_14.png"
         title="Example of multi filter 3-D convolution"
         alt="Image of example of multi filter 3-D convolution"
         class="img_center"
         style="width: 70%"/>
    <figcaption>여러 필터를 사용한 3차원 합성곱 연산의 예</figcaption>
</figure>

[Fig. 12.]는 필터를 FN개 사용한 합성곱 연산의 예시입니다. 필터를 FN개 적용하면 출력 특징 맵도 FN개가 생성됩니다. 그리고 그 FN개의 맵을 모으면 형상이 (FN, OH, OW)인 블록이 완성됩니다. 이 완성된 블록을 다음 계층으로 넘기겠다는 것이 CNN의 처리 흐름입니다. 따라서 CNN의 합성곱 연산에서는 필터의 수도 고려해야 합니다. 그런 이유로 필터의 가중치 데이터는 4차원 데이터이며 (**출력 채널 수**<sup>FN</sup>, **입력 채널 수**<sup>C</sup>, **높이**<sup>FH</sup>, **너비**<sup>FW</sup>) 순서로 표기합니다.

3차원 합성곱 연산에도 마찬가지로 **편향**이 쓰입니다. 이를 완성하면 아래와 같습니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_15.png"
         title="Bias of multi filter 3-D convolution"
         alt="Image of bias of multi filter 3-D convolution"
         class="img_center"
         style="width: 70%"/>
    <figcaption>여러 필터를 사용한 3차원 합성곱 연산의 편향</figcaption>
</figure>

[Fig. 13.]에서 보듯 편향은 채널 **하나**에 값 **하나**씩으로 구성됩니다. 형상이 다른 두 블록의 덧셈은 Python의 numpy 모듈의 브로드캐스트 기능으로 구현할 수 있기에 위와 같이 나타내었습니다.

## 배치 처리

신경망 처리에서는 입력 데이터를 한 덩이로 묶어 **배치**로 처리했습니다. **완전연결** 신경망을 구현하면서는 이 방식을 지원하여 처리 효율을 높이고, **미니배치** 방식의 학습도 지원하도록 했습니다.

합성곱 연산도 마찬가지로 배치 처리를 지원하고자 합니다. 그래서 각 계층을 흐르는 데이터의 차원을 하나 늘려 4차원 데이터로 저장합니다. 구체적으로는 데이터를 (**데이터 수**<sup>N</sup>, **채널 수**<sup>C</sup>, **높이**<sup>H</sup>, **너비**<sup>W</sup>) 순으로 저장합니다. 데이터가 **N**개일 때 [Fig. 13.]을 배치 처리한다면 아래와 같이 데이터 형태를 나타낼 수 있습니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_16.png"
         title="Batch of multi filter 3-D convolution"
         alt="Image of batch of multi filter 3-D convolution"
         class="img_center"
         style="width: 70%"/>
    <figcaption>3차원 합성곱 연산의 배치 처리</figcaption>
</figure>

[Fig. 14.]에서는 배치 처리 시 각 데이터의 선두에 배치용 차원을 추가했습니다. 이처럼 데이터는 4차원 형상을 가진 채 각 계층을 타고 흐릅니다. 여기에서 주의할 점으로는 신경망에 4차원 데이터가 하나 흐를 때마다 데이터 **N**개에 대한 합성곱 연산이 이뤄진다는 것입니다. 즉, **N**회 분의 처리를 한 번에 수행하는 것입니다.