---
layout: post
title: Convolutional Neural Network (CNN)-2
category: deep learning
post-series: Deep learning from scratch
post-order: 20
---

이전 [post](https://gyuhub.github.io/posts/study/machine%20learning/deep%20learning/cnn-1)에서는 **CNN**과 **합성곱 계층**에 대해서 배웠습니다. 이번 post에서는 풀링 계층을 설명하고 CNN을 구현해보겠습니다.

---

# 풀링 계층

**풀링**(pooling)은 세로 &bull; 가로 방향의 **공간**을 **줄이는** 연산입니다. 예를 하나 들어보겠습니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_17.png"
         title="Example of max pooling"
         alt="Image of example of max pooling"
         class="img_center"
         style="width: 60%"/>
    <figcaption>풀링(최대 풀링) 연산의 예</figcaption>
</figure>

[Fig. 1.]은 (2x2) 영역을 원소 하나로 집약하여 공간의 크기를 줄인 풀링(최대 풀링) 연산의 예시입니다. 좀 더 연산 과정을 들여다 보겠습니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_18.gif"
         title="Computation order of max pooling"
         alt="Image of computation order of max pooling"
         class="img_center"
         style="width: 60%"/>
    <figcaption>최대 풀링 연산의 계산 순서</figcaption>
</figure>

[Fig. 2.]는 2X2 **최대 풀링**(max pooling)을 **스트라이드 2**로 처리하는 순서입니다. 최대 풀링은 **최댓값**(max)을 구하는 연산으로, '2x2'는 대상 영역의 크기를 뜻합니다. 즉 2x2 최대 풀링은 그림과 같이 2x2 크기의 영역에서 가장 큰 원소 하나를 꺼냅니다. 또, **스트라이드**는 이 예에서는 **2**로 설정했으므로 (2x2) 윈도우가 원소 **2칸** 간격으로 이동합니다. 참고로, <ins>풀링의 윈도우 크기</ins>와 <ins>스트라이드</ins>는 **같은 값**으로 설정하는 것이 보통의 관례입니다.

> ➕ 풀링은 최대 풀링 외에도 **평균 풀링**(average pooling) 등이 있습니다. 최대 풀링은 대상 영역에서 **최댓값**을 취하는 연산인 반면, 평균 풀링은 대상 영역의 **평균**을 계산합니다. 이미지 인식 분야에서는 주로 **최대 풀링**을 사용합니다.

그렇다면 풀링 계층의 특징은 과연 무엇일까요?

* 학습해야 할 매개변수가 **없다**
  * 풀링 계층은 합성곱 계층과 달리 학습해야 할 매개변수가 없습니다. 풀링은 대상 영역에서 최댓값이나 평균을 취하는 **명확한** 처리이므로 특별히 학습할 것이 없습니다.
* **채널 수**가 변하지 않는다
  * 풀링 연산은 입력 데이터의 채널 수 그대로 출력 데이터로 내보냅니다. 아래의 예시와 같이 채널마다 독립적으로 계산하기 때문입니다.
  * <figure>
        <img src="/posts/study/machine learning/deep learning/images/cnn_19.png"
             title="Computation property of pooling layer"
             alt="Image of computation property of pooling layer"
             class="img_center"
             style="width: 60%"/>
        <figcaption>채널 수를 바꾸지 않는 풀링 연산</figcaption>
    </figure>
* 입력의 변화에 영향을 **적게** 받는다 (**강건하다**)
  * 입력 데이터가 조금 변해도 풀링의 결과는 잘 변하지 **않습니다**. 예를 들어 아래의 예시처럼 입력 데이터의 차이(데이터가 오른쪽으로 1칸씩 이동)를 최대 풀링이 흡수해 사라지게 하는 모습을 보여줍니다.
  * <figure>
        <img src="/posts/study/machine learning/deep learning/images/cnn_20.png"
             title="Robustness of pooling layer"
             alt="Image of robustness of pooling layer"
             class="img_center"
             style="width: 60%"/>
        <figcaption>풀링 연산의 강건함</figcaption>
    </figure>

---

# CNN 구현

지금까지 합성곱 계층과 풀링 계층에 대해서 자세히 알아봤습니다. CNN을 구현하기에 앞서 이 두 계층을 먼저 구현하겠습니다.

## 합성곱 계층

이전에 설명한 대로 CNN에서 계층 사이를 흐르는 데이터는 **4차원**입니다. 예를 들어 입력 데이터가 너비 28, 높이 28, 채널 1개, 데이터가 10개인 이미지인 경우에는 (10, 1, 28, 28)과 같이 표현할 수 있겠습니다. 이러한 4차원 데이터에 합성곱 연산을 곧이곧대로 구현하려면 수많은 **for문**을 사용해야 하기 때문에 굉장히 **비효율적**일겁니다. 따라서 대부분의 선형 대수 라이브러리가 **거대한 행렬** 계산에 고도로 **최적화**되어 큰 행렬의 곱셈이 **빠른** 점을 이용할 예정입니다.

바로 **im2col**(image to column)이라는 method를 사용하는 것입니다. im2col은 입력 데이터를 필터링(가중치 계산)하기 좋게 전개하는 함수입니다. 입력 데이터가 4차원일때 이를 길게 펼쳐서 **2차원**의 행렬로 바꿔주는 것입니다. 합성곱 계층의 필터도 마찬가지로 **2차원**으로 바꿔서 이 두 행렬의 곱을 계산하고 다시 원래의 형태(4차원)로 복원시켜서 합성곱 연산을 구현하게 됩니다. 많은 딥러닝 프레임워크들은 im2col이라는 이름의 method를 구현해서 합성곱 계층을 구현할 때 이용하고 있지만, Python의 numpy 모듈에는 기본적으로 구현되어 있지 않습니다. 따라서 입력 데이터가 이미지인 경우에 활용할 수 있는 im2col method를 직접 구현하겠습니다.

im2col의 원리는 다음과 같습니다. 각각의 데이터의 크기를 입력 데이터가 $(N, C, H, W)$, 필터가 $(FN, C, FH, FW)$, 스트라이드가 $S$, 패딩이 $P$라 할때 합성곱 연산의 출력 데이터의 크기는 $(N, FN, OH, OW)$이고 수식으로는 다음과 같습니다.

$$
OH = \frac{H + 2P - FH}{S} + 1 \\
OW = \frac{W + 2P - FW}{S} + 1 \tag{1}
$$

필터와 입력 데이터의 채널 수가 같아야 하고 $FN$개의 필터가 입력 데이터에 곱해져서 출력 데이터의 채널 수가 된다는 점을 고려하면, 입력 데이터에 im2col 연산을 취한 후의 크기는 $(N\times OH\times OW, C\times FH \times FW)$입니다. 합성곱 연산의 필터 처리 상세 과정은 아래와 같습니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_21.png"
         title="Computational process of convolution layer"
         alt="Image of computational process of convolution layer"
         class="img_center"
         style="width: 70%"/>
    <figcaption>합성곱 연산의 필터 처리 과정 구현</figcaption>
</figure>

그럼 Python을 이용해서 im2col method를 구현해보겠습니다.
```python
def im2col(input_data, filter_h, filter_w, stride=1, pad=0):
    """convert multi dimensional image into 2-dimensions image(flattening).
    
    Parameters
    ----------
    input_data : 4-dimensions input image(number of images, number of channels, height of image, width of image)
    filter_h : height of filter
    filter_w : width of filter
    stride : stride of filter
    pad : padding of input image
    
    Returns
    -------
    col : 2-dimensional array(column-wise)
    """
    N, C, H, W = input_data.shape
    OH = int((H + 2 * pad - filter_h) // stride + 1)
    OW = int((W + 2 * pad - filter_w) // stride + 1)

    img = np.pad(input_data, [(0, 0), (0, 0), (pad, pad), (pad, pad)], 'constant')
    col = np.zeros((N, C, filter_h, filter_w, OH, OW))

    for y in range(filter_h):
        y_max = y * stride + OH
        for x in range(filter_w):
            x_max = x * stride + OW
            col[:, :, y, x, :, :] = img[:, :, y*stride : y_max, x*stride : x_max]

    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N * OH * OW, C * filter_h * filter_w)
    return col
```

그럼 이제 im2col을 사용해서 합성곱 계층을 구현해보겠습니다.
```python
class ConvolutionLayer:
    def __init__(self, W, b, stride=1, pad=0):
        self.W = W
        self.b = b
        self.stride = stride
        self.pad = pad

        # used when backward
        self.x = None
        self.col = None
        self.col_W = None
        self.dW = None
        self.db = None

    def forward(self, x):
        N, C, H, W = x.shape
        FN, C, FH, FW = self.W.shape
        OH = int((H + 2 * self.pad - FH) // self.stride + 1)
        OW = int((W + 2 * self.pad - FW) // self.stride + 1)

        col = im2col(x, FH, FW, self.stride, self.pad)
        col_W = self.W.reshape(C * FH * FW, FN)
        out = np.dot(col, col_W) + self.b

        out = out.reshape(N, OH, OW, FN).transpose(0, 3, 1, 2)
        self.x = x
        self.col = col
        self.col_W = col_W
        return out
    
    def backward(self, dout):
        FN, C, FH, FW = self.W.shape
        dout = dout.transpose(0, 2, 3, 1).reshape(-1, FN)

        self.db = np.sum(dout, axis=0)
        self.dW = np.dot(self.col.T, dout)
        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)

        dcol = np.dot(dout, self.col_W.T)
        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)
        return dx
```

합성곱 계층의 forward와 backward는 im2col이라는 method덕분에 사실상 **Affine 계층**의 forward와 backward와 거의 유사합니다. 다만 forward시에 im2col으로 이미지의 **형변환**이 이뤄지기에, backward시에는 col2im라는 method를 추가적으로 구현해서 다시 형상을 **복원**해줘야 합니다. col2im의 구현은 [여기](https://github.com/Gyuhub/dl_scratch/blob/main/dl_scratch/common/utils.py#L34)를 참고해주시면 감사하겠습니다.

## 풀링 계층

풀링 계층도 합성곱 계층과 마찬가지로 **im2col**을 사용해 입력 데이터를 펼칩니다. 단, 풀링의 경우엔 **채널 쪽**이 **독립적**이라는 점이 합성곱 계층 때와 다릅니다. 구체적으로는 아래의 그림과 같이 풀링 적용 영역을 **채널마다** **독립적**으로 전개합니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_22.png"
         title="After applying im2col method in pooling layer to input data"
         alt="Image after applying im2col method in pooling layer to input data"
         class="img_center"
         style="width: 60%"/>
    <figcaption>입력 데이터에 풀링 계층(2x2)의 im2col method를 적용한 예</figcaption>
</figure>

[Fig. 6.]과 같이 입력 데이터를 전개한 후, 전개한 행렬에서 **행별 최댓값**을 구하고 아래와 같이 적절한 형상으로 **변형**합니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_23.png"
         title="Flow of pooling layer implementation"
         alt="Image of flow of pooling layer implementation"
         class="img_center"
         style="width: 60%"/>
    <figcaption>풀링 계층 구현의 흐름</figcaption>
</figure>

[Fig. 7.]을 Python으로 구현한 코드는 다음과 같습니다.
```python
class PoolingLayer:
    def __init__(self, pool_h, pool_w, stride=1, pad=0):
        self.pool_h = pool_h
        self.pool_w = pool_w
        self.stride = stride
        self.pad = pad

        # used when backward
        self.x = None
        self.arg_max = None

    def forward(self, x):
        N, C, H, W = x.shape
        OH = int((H - self.pool_h) // self.stride + 1)
        OW = int((W - self.pool_w) // self.stride + 1)

        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)
        col = col.reshape(-1, self.pool_h * self.pool_w)

        arg_max = np.argmax(col, axis=1)
        out = np.max(col, axis=1)
        out = out.reshape(N, OH, OW, C).transpose(0, 3, 1, 2)

        self.x = x
        self.arg_max = arg_max
        return out

    def backward(self, dout):
        dout.transpose(0, 2, 3, 1)

        pool_size = self.pool_h * self.pool_w
        dmax = np.zeros((dout.size, pool_size))
        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()
        dmax = dmax.reshape(dout.shape + (pool_size,))

        dcol = dmax.reshape(dout.shape[0] * dmax.shape[1] * dmax.shape[2], -1)
        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)
        return dx
```

## 단순 합성곱 신경망 구현

합성곱 계층과 풀링 계층을 구현했으니, 이 계층들을 조합하여 손글씨 숫자를 인식하는 다소 간단한 CNN을 구현해보겠습니다. 신경망의 구조는 아래와 같습니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_24.png"
         title="Network configuration of simple CNN"
         alt="Image of network configuration of simple CNN"
         class="img_center"
         style="width: 70%"/>
    <figcaption>단순한 CNN의 네트워크 구성</figcaption>
</figure>

이제 손글씨 숫자를 학습하는 신경망을 구현해보겠습니다. MNIST 데이터셋을 가지고 **학습**을 진행하는 CNN의 구조는 아래와 같습니다.

- 입력층의 뉴런 784개 (1x28x28 pixels)
- 합성곱 계층의 필터의 크기 5x5, 필터의 숫자 30개, 스트라이드 1, 패딩 0
- 풀링 계층의 필터의 크기 2x2, 스트라이드 2
- 완전연결 계층의 뉴런의 개수 100개
- 출력층의 뉴런 10개 (0에서 9까지의 숫자)
- 활성화 함수는 ReLU 함수, 출력층 활성화 함수는 소프트맥스 함수
- 가중치 매개변수는 정규분포를 따르고 표준편차가 0.01인 난수, 편향 매개변수는 0으로 초기화
- 손실 함수는 교차 엔트로피 오차 함수
- 미니배치의 크기는 100, 학습률은 0.1, 경사법에 의한 갱신 횟수는 10,000
- 훈련 데이터의 크기는 60,000, 시험 데이터의 크기는 10,000

> :smiley: 자세한 코드는 Git 저장소[^fn-train-conv-net]를 통해 확인해주시기 바랍니다.

아래의 그림은 손실 함수의 값의 변화를 기록한 그래프입니다.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/cnn_25.png"
         title="Graph of loss function"
         alt="Image of graph of loss function"
         class="img_center"
         style="width: 50%"/>
    <figcaption>학습에 의한 손실 함수값의 변화</figcaption>
</figure>

[Fig. 9.]를 보면 학습 횟수가 늘어나면서 손실 함수값이 줄어듭니다. 이는 학습이 잘 되고 있다는 뜻으로, 신경망의 가중치 매개변수가 서서히 데이터에 적응하고 있음을 의미합니다. 신경망이 학습을 하고 있다는 의미입니다. 또한 상당히 적은 횟수의 에폭만으로도 정확도가 꽤 높아진 것을 확인할 수 있습니다.

또한, CNN은 합성곱 계층의 필터를 통해서 이미지의 에지나 블롭(blob) 등의 **원시적인** 정보를 추출할 수 있습니다. 이러한 원시적인 정보가 뒷단 계층에 **차례대로** 전달됩니다. 또한, 딥러닝 시각화에 관한 연구[^fn-visualize-cnn-1][^fn-visualize-cnn-2]에 따르면, 계층이 깊어질수록 추출되는 정보(정확히는 강하게 반응하는 뉴런)는 더 **추상화**된다는 것을 알 수 있습니다. 딥러닝의 흥미로운 점은 합성곱 계층을 **여러 겹** 쌓으면, 층이 깊어지면서 더 **복잡하고** **추상화된** 정보가 추출된다는 것입니다. 처음 층은 단순한 **에지**에 반응하고, 이어서 **텍스처**에 반응하고, 더 복잡한 **사물의 일부**에 반응하도록 변화합니다. 측, 층이 깊어지면서 뉴런이 반응하는 대상이 단순한 모양에서 '**고급**' 정보로 변화해갑니다. 다시 말하면 사물의 '**의미**'를 이해하도록 변화하는 것입니다.

지금까지 CNN의 기초와 이론, 구현까지 정리해봤습니다.

## CNN 요약
- CNN은 지금까지의 완전연결 계층 네트워크에 합성곱 계층과 풀링 계층을 새로 추가한다.
- 합성곱 계층과 풀링 계층은 im2col(이미지를 행렬로 전개하는 함수)를 이용하면 간단하고 효율적으로 구현할 수 있다.
- CNN을 시각화해보면 계층이 깊어질수록 고급 정보가 추출되는 모습을 확인할 수 있다.

---

[^fn-train-conv-net]: CNN 학습과 관련된 코드는 [여기](https://www.github.com/Gyuhub/dl_scratch/blob/main/ch7/train_conv_net.py)를 참고해주시면 감사하겠습니다.

[^fn-visualize-cnn-1]: Zeiler, Matthew D., and Rob Fergus. "Visualizing and understanding convolutional networks." Computer Vision–ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part I 13. Springer International Publishing, 2014.

[^fn-visualize-cnn-2]: Mahendran, Aravindh, and Andrea Vedaldi. "Understanding deep image representations by inverting them." Proceedings of the IEEE conference on computer vision and pattern recognition. 2015.